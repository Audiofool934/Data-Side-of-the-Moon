{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "import pandas as pd\n",
    "\n",
    "from utility import get_all_files_paths\n",
    "from encoder import Encoder, load_encoder\n",
    "from decoder import Decoder, load_decoder\n",
    "from train import train_epoch, test_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_path=\"data/spec/fma_small\"\n",
    "dataset_path = \"data/spec/GTZAN_646\"\n",
    "model_save_path = \"models/Echoes\"\n",
    "csv_save_path = \"output/Echoes_output\"\n",
    "encoded_space_dim = 128\n",
    "\n",
    "os.makedirs(model_save_path, exist_ok=True)\n",
    "os.makedirs(csv_save_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 720\n",
      "Validation set size: 80\n",
      "Test set size: 200\n"
     ]
    }
   ],
   "source": [
    "class AudioDataset(Dataset):\n",
    "    def __init__(self, file_paths):\n",
    "        self.file_paths = file_paths\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file_path = self.file_paths[idx]\n",
    "        data = np.load(file_path)\n",
    "        data = data[np.newaxis, :, :]  # Add a channel dimension\n",
    "        data = torch.tensor(data, dtype=torch.float32)\n",
    "        \n",
    "        # Extract label from file name\n",
    "        filename = os.path.basename(file_path)\n",
    "        label_str = filename.split('.')[0]\n",
    "        label = self.label_to_index(label_str)\n",
    "        \n",
    "        return data, label\n",
    "\n",
    "    @staticmethod\n",
    "    def label_to_index(label_str):\n",
    "        label_map = {'blues': 'blues', 'disco': 'disco', 'rock': 'rock', 'metal': 'metal', 'classical': 'classical', 'pop': 'pop', 'reggae':'reggae','country':'country', 'hiphop':'hiphop', 'jazz':'jazz'}  # Extend this as needed\n",
    "        # label_map = {'Blues': 'Blues', 'Classical': 'Classical', 'Country': 'Country', 'Electronic': 'Electronic', 'Experimental': 'Experimental', 'Folk': 'Folk', 'genre_unknown':'genre_unknown','Instrumental':'Instrumental', 'Hip-Hop':'Hip-Hop', 'International':'International', 'Jazz':'Jazz', 'Pop':'Pop', 'Rock':'Rock', 'Soul-RnB':'Soul-RnB', 'Spoken':'Spoken'}  # Extend this as needed\n",
    "        return label_map.get(label_str, -1)  # Return -1 if label is not found\n",
    "\n",
    "genres = ['blues', 'disco', 'rock', 'metal', 'pop', 'classical', 'reggae', 'country','hiphop','jazz']\n",
    "# genres = ['Blues', 'Blues', 'rock', 'Classical', 'Country', 'Electronic', 'Experimental', 'Folk','genre_unknown','Instrumental', 'Hip-Hop', 'International', 'Jazz', 'Pop', 'Rock', 'Soul-RnB', 'Spoken']\n",
    "\n",
    "genre_file_paths = {genre: get_all_files_paths(f\"{dataset_path}/{genre}\", [\".npy\"]) for genre in genres}\n",
    "\n",
    "train_file_paths = []\n",
    "valid_file_paths = []\n",
    "test_file_paths = []\n",
    "\n",
    "for genre, paths in genre_file_paths.items():\n",
    "    m = len(paths)\n",
    "    test_size = int(m * 0.2)\n",
    "    valid_size = int((m - test_size) * 0.1)\n",
    "    train_size = m - test_size - valid_size\n",
    "    \n",
    "    paths = np.array(paths)\n",
    "    np.random.shuffle(paths)\n",
    "    \n",
    "    train_paths = paths[:train_size]\n",
    "    valid_paths = paths[train_size:train_size + valid_size]\n",
    "    test_paths = paths[train_size + valid_size:]\n",
    "    \n",
    "    train_file_paths.extend(train_paths)\n",
    "    valid_file_paths.extend(valid_paths)\n",
    "    test_file_paths.extend(test_paths)\n",
    "\n",
    "train_dataset = AudioDataset(train_file_paths)\n",
    "valid_dataset = AudioDataset(valid_file_paths)\n",
    "test_dataset = AudioDataset(test_file_paths)\n",
    "\n",
    "batch_size = 128\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "print(f'Training set size: {len(train_dataset)}')\n",
    "print(f'Validation set size: {len(valid_dataset)}')\n",
    "print(f'Test set size: {len(test_dataset)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Decoder(\n",
       "  (decoder_lin): Sequential(\n",
       "    (0): Linear(in_features=128, out_features=512, bias=True)\n",
       "    (1): LeakyReLU(negative_slope=0.05, inplace=True)\n",
       "    (2): Linear(in_features=512, out_features=167936, bias=True)\n",
       "    (3): LeakyReLU(negative_slope=0.05, inplace=True)\n",
       "    (4): Dropout(p=0.3, inplace=False)\n",
       "  )\n",
       "  (unflatten): Unflatten(dim=1, unflattened_size=(256, 16, 41))\n",
       "  (decoder_conv): Sequential(\n",
       "    (0): ConvTranspose2d(256, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 0))\n",
       "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): LeakyReLU(negative_slope=0.05, inplace=True)\n",
       "    (3): ConvTranspose2d(128, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): LeakyReLU(negative_slope=0.05, inplace=True)\n",
       "    (6): ConvTranspose2d(64, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 0))\n",
       "    (7): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (8): LeakyReLU(negative_slope=0.05, inplace=True)\n",
       "    (9): ConvTranspose2d(32, 1, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Define the loss function\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "\n",
    "### Define an optimizer (both for the encoder and the decoder)\n",
    "lr = 1e-5\n",
    "\n",
    "### Set the random seed for reproducible results\n",
    "torch.manual_seed(0)\n",
    "\n",
    "#model = Autoencoder(encoded_space_dim=encoded_space_dim)\n",
    "encoder = Encoder(encoded_space_dim=encoded_space_dim)\n",
    "decoder = Decoder(encoded_space_dim=encoded_space_dim)\n",
    "params_to_optimize = [\n",
    "    {'params': encoder.parameters()},\n",
    "    {'params': decoder.parameters()}\n",
    "]\n",
    "\n",
    "optim = torch.optim.Adam(params_to_optimize, lr=lr, weight_decay=1e-05)\n",
    "\n",
    "# Check if the GPU is available\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(f'device: {device}')\n",
    "\n",
    "# Move both the encoder and the decoder to the selected device\n",
    "encoder.to(device)\n",
    "decoder.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " EPOCH 1/500 \t train loss 1.3892775774002075 \t val loss 0.3352344334125519\n",
      "\n",
      " EPOCH 2/500 \t train loss 1.2183080911636353 \t val loss 0.3333692252635956\n",
      "\n",
      " EPOCH 3/500 \t train loss 1.0751334428787231 \t val loss 0.35226869583129883\n",
      "\n",
      " EPOCH 4/500 \t train loss 0.952137291431427 \t val loss 0.44902241230010986\n",
      "\n",
      " EPOCH 5/500 \t train loss 0.8471887111663818 \t val loss 0.5038152933120728\n",
      "\n",
      " EPOCH 6/500 \t train loss 0.7564983367919922 \t val loss 0.49795499444007874\n",
      "\n",
      " EPOCH 7/500 \t train loss 0.6790043711662292 \t val loss 0.4658529460430145\n",
      "\n",
      " EPOCH 8/500 \t train loss 0.6109701991081238 \t val loss 0.4285334050655365\n",
      "\n",
      " EPOCH 9/500 \t train loss 0.5520099401473999 \t val loss 0.3951238691806793\n",
      "\n",
      " EPOCH 10/500 \t train loss 0.5021452903747559 \t val loss 0.3622402548789978\n",
      "\n",
      " EPOCH 11/500 \t train loss 0.4572185277938843 \t val loss 0.33406877517700195\n",
      "\n",
      " EPOCH 12/500 \t train loss 0.4177480936050415 \t val loss 0.3079608976840973\n",
      "\n",
      " EPOCH 13/500 \t train loss 0.384197473526001 \t val loss 0.28419727087020874\n",
      "\n",
      " EPOCH 14/500 \t train loss 0.3527638018131256 \t val loss 0.2655406594276428\n",
      "\n",
      " EPOCH 15/500 \t train loss 0.32556501030921936 \t val loss 0.2462611198425293\n",
      "\n",
      " EPOCH 16/500 \t train loss 0.3018498718738556 \t val loss 0.2304878681898117\n",
      "\n",
      " EPOCH 17/500 \t train loss 0.28011149168014526 \t val loss 0.21707522869110107\n",
      "\n",
      " EPOCH 18/500 \t train loss 0.2625562250614166 \t val loss 0.20368459820747375\n",
      "\n",
      " EPOCH 19/500 \t train loss 0.24607837200164795 \t val loss 0.1924164891242981\n",
      "\n",
      " EPOCH 20/500 \t train loss 0.2309110164642334 \t val loss 0.18227897584438324\n",
      "\n",
      " EPOCH 21/500 \t train loss 0.21809332072734833 \t val loss 0.17320428788661957\n",
      "\n",
      " EPOCH 22/500 \t train loss 0.20666541159152985 \t val loss 0.16501761972904205\n",
      "\n",
      " EPOCH 23/500 \t train loss 0.19642890989780426 \t val loss 0.1577014923095703\n",
      "\n",
      " EPOCH 24/500 \t train loss 0.1875201314687729 \t val loss 0.15086254477500916\n",
      "\n",
      " EPOCH 25/500 \t train loss 0.1794803887605667 \t val loss 0.14482669532299042\n",
      "\n",
      " EPOCH 26/500 \t train loss 0.17348487675189972 \t val loss 0.13936074078083038\n",
      "\n",
      " EPOCH 27/500 \t train loss 0.1645532101392746 \t val loss 0.1340761035680771\n",
      "\n",
      " EPOCH 28/500 \t train loss 0.15907900035381317 \t val loss 0.12900400161743164\n",
      "\n",
      " EPOCH 29/500 \t train loss 0.15250371396541595 \t val loss 0.12485284358263016\n",
      "\n",
      " EPOCH 30/500 \t train loss 0.14751788973808289 \t val loss 0.12032850831747055\n",
      "\n",
      " EPOCH 31/500 \t train loss 0.14302363991737366 \t val loss 0.11612217873334885\n",
      "\n",
      " EPOCH 32/500 \t train loss 0.1372395008802414 \t val loss 0.11240796744823456\n",
      "\n",
      " EPOCH 33/500 \t train loss 0.13348576426506042 \t val loss 0.10945389419794083\n",
      "\n",
      " EPOCH 34/500 \t train loss 0.129731684923172 \t val loss 0.10601189732551575\n",
      "\n",
      " EPOCH 35/500 \t train loss 0.12603141367435455 \t val loss 0.10322687029838562\n",
      "\n",
      " EPOCH 36/500 \t train loss 0.12172556668519974 \t val loss 0.10000038892030716\n",
      "\n",
      " EPOCH 37/500 \t train loss 0.11795615404844284 \t val loss 0.09721951931715012\n",
      "\n",
      " EPOCH 38/500 \t train loss 0.11391151696443558 \t val loss 0.09405940771102905\n",
      "\n",
      " EPOCH 39/500 \t train loss 0.11141619086265564 \t val loss 0.09177439659833908\n",
      "\n",
      " EPOCH 40/500 \t train loss 0.108077771961689 \t val loss 0.0885329470038414\n",
      "\n",
      " EPOCH 41/500 \t train loss 0.1057969331741333 \t val loss 0.08639421314001083\n",
      "\n",
      " EPOCH 42/500 \t train loss 0.10187012702226639 \t val loss 0.08391905575990677\n",
      "\n",
      " EPOCH 43/500 \t train loss 0.09941301494836807 \t val loss 0.08138804137706757\n",
      "\n",
      " EPOCH 44/500 \t train loss 0.0974043682217598 \t val loss 0.08053978532552719\n",
      "\n",
      " EPOCH 45/500 \t train loss 0.0947783887386322 \t val loss 0.07764583081007004\n",
      "\n",
      " EPOCH 46/500 \t train loss 0.09207868576049805 \t val loss 0.07601551711559296\n",
      "\n",
      " EPOCH 47/500 \t train loss 0.08982103317975998 \t val loss 0.0747399628162384\n",
      "\n",
      " EPOCH 48/500 \t train loss 0.08757580071687698 \t val loss 0.0727415606379509\n",
      "\n",
      " EPOCH 49/500 \t train loss 0.08544906973838806 \t val loss 0.0704309493303299\n",
      "\n",
      " EPOCH 50/500 \t train loss 0.0835191085934639 \t val loss 0.06886614114046097\n",
      "\n",
      " EPOCH 51/500 \t train loss 0.08152730017900467 \t val loss 0.06652289628982544\n",
      "\n",
      " EPOCH 52/500 \t train loss 0.07962653785943985 \t val loss 0.06498701125383377\n",
      "\n",
      " EPOCH 53/500 \t train loss 0.07783020287752151 \t val loss 0.0635773092508316\n",
      "\n",
      " EPOCH 54/500 \t train loss 0.07657243311405182 \t val loss 0.06292472779750824\n",
      "\n",
      " EPOCH 55/500 \t train loss 0.0743996873497963 \t val loss 0.06053174287080765\n",
      "\n",
      " EPOCH 56/500 \t train loss 0.0731908455491066 \t val loss 0.060141850262880325\n",
      "\n",
      " EPOCH 57/500 \t train loss 0.07174282521009445 \t val loss 0.059447359293699265\n",
      "\n",
      " EPOCH 58/500 \t train loss 0.07000961154699326 \t val loss 0.05776779353618622\n",
      "\n",
      " EPOCH 59/500 \t train loss 0.068933866918087 \t val loss 0.05661126598715782\n",
      "\n",
      " EPOCH 60/500 \t train loss 0.06690985709428787 \t val loss 0.05459575355052948\n",
      "\n",
      " EPOCH 61/500 \t train loss 0.06564801186323166 \t val loss 0.05494382232427597\n",
      "\n",
      " EPOCH 62/500 \t train loss 0.06421912461519241 \t val loss 0.05280577763915062\n",
      "\n",
      " EPOCH 63/500 \t train loss 0.06357549875974655 \t val loss 0.05242396891117096\n",
      "\n",
      " EPOCH 64/500 \t train loss 0.06213837489485741 \t val loss 0.04995865002274513\n",
      "\n",
      " EPOCH 65/500 \t train loss 0.061389196664094925 \t val loss 0.050037384033203125\n",
      "\n",
      " EPOCH 66/500 \t train loss 0.0599319152534008 \t val loss 0.04920273274183273\n",
      "\n",
      " EPOCH 67/500 \t train loss 0.05903053656220436 \t val loss 0.04800984635949135\n",
      "\n",
      " EPOCH 68/500 \t train loss 0.0581071712076664 \t val loss 0.04662177339196205\n",
      "\n",
      " EPOCH 69/500 \t train loss 0.05699646845459938 \t val loss 0.04588614031672478\n",
      "\n",
      " EPOCH 70/500 \t train loss 0.05590888857841492 \t val loss 0.045968081802129745\n",
      "\n",
      " EPOCH 71/500 \t train loss 0.054893359541893005 \t val loss 0.04634762182831764\n",
      "\n",
      " EPOCH 72/500 \t train loss 0.05427531898021698 \t val loss 0.045481082051992416\n",
      "\n",
      " EPOCH 73/500 \t train loss 0.053309366106987 \t val loss 0.0438641682267189\n",
      "\n",
      " EPOCH 74/500 \t train loss 0.05260542035102844 \t val loss 0.04470176622271538\n",
      "\n",
      " EPOCH 75/500 \t train loss 0.05166316032409668 \t val loss 0.0426957793533802\n",
      "\n",
      " EPOCH 76/500 \t train loss 0.05029202625155449 \t val loss 0.041188210248947144\n",
      "\n",
      " EPOCH 77/500 \t train loss 0.049726452678442 \t val loss 0.041022900491952896\n",
      "\n",
      " EPOCH 78/500 \t train loss 0.049174413084983826 \t val loss 0.040608812123537064\n",
      "\n",
      " EPOCH 79/500 \t train loss 0.04819194972515106 \t val loss 0.03975805267691612\n",
      "\n",
      " EPOCH 80/500 \t train loss 0.047456879168748856 \t val loss 0.039047617465257645\n",
      "\n",
      " EPOCH 81/500 \t train loss 0.04703432694077492 \t val loss 0.03853827342391014\n",
      "\n",
      " EPOCH 82/500 \t train loss 0.04603523388504982 \t val loss 0.038249384611845016\n",
      "\n",
      " EPOCH 83/500 \t train loss 0.045660167932510376 \t val loss 0.03797239437699318\n",
      "\n",
      " EPOCH 84/500 \t train loss 0.044825565069913864 \t val loss 0.03631875291466713\n",
      "\n",
      " EPOCH 85/500 \t train loss 0.044233810156583786 \t val loss 0.03597186878323555\n",
      "\n",
      " EPOCH 86/500 \t train loss 0.04402463510632515 \t val loss 0.03554696962237358\n",
      "\n",
      " EPOCH 87/500 \t train loss 0.0431927889585495 \t val loss 0.036102816462516785\n",
      "\n",
      " EPOCH 88/500 \t train loss 0.04234647750854492 \t val loss 0.03516745939850807\n",
      "\n",
      " EPOCH 89/500 \t train loss 0.04174149036407471 \t val loss 0.033980779349803925\n",
      "\n",
      " EPOCH 90/500 \t train loss 0.04118965193629265 \t val loss 0.03389175236225128\n",
      "\n",
      " EPOCH 91/500 \t train loss 0.0408925786614418 \t val loss 0.033346205949783325\n",
      "\n",
      " EPOCH 92/500 \t train loss 0.04038935527205467 \t val loss 0.03271380811929703\n",
      "\n",
      " EPOCH 93/500 \t train loss 0.03962724655866623 \t val loss 0.03251619264483452\n",
      "\n",
      " EPOCH 94/500 \t train loss 0.03928282484412193 \t val loss 0.03192223235964775\n",
      "\n",
      " EPOCH 95/500 \t train loss 0.038780637085437775 \t val loss 0.031582411378622055\n",
      "\n",
      " EPOCH 96/500 \t train loss 0.038339052349328995 \t val loss 0.03163718432188034\n",
      "\n",
      " EPOCH 97/500 \t train loss 0.037845294922590256 \t val loss 0.031009584665298462\n",
      "\n",
      " EPOCH 98/500 \t train loss 0.03741699829697609 \t val loss 0.030429642647504807\n",
      "\n",
      " EPOCH 99/500 \t train loss 0.036769669502973557 \t val loss 0.030280956998467445\n",
      "\n",
      " EPOCH 100/500 \t train loss 0.036486413329839706 \t val loss 0.030494598671793938\n",
      "\n",
      " EPOCH 101/500 \t train loss 0.035955581814050674 \t val loss 0.029497738927602768\n",
      "\n",
      " EPOCH 102/500 \t train loss 0.035471249371767044 \t val loss 0.029317231848835945\n",
      "\n",
      " EPOCH 103/500 \t train loss 0.03516117483377457 \t val loss 0.029195353388786316\n",
      "\n",
      " EPOCH 104/500 \t train loss 0.035011570900678635 \t val loss 0.028735434636473656\n",
      "\n",
      " EPOCH 105/500 \t train loss 0.03435540199279785 \t val loss 0.028115607798099518\n",
      "\n",
      " EPOCH 106/500 \t train loss 0.033979322761297226 \t val loss 0.027850935235619545\n",
      "\n",
      " EPOCH 107/500 \t train loss 0.033488985151052475 \t val loss 0.027367400005459785\n",
      "\n",
      " EPOCH 108/500 \t train loss 0.033099912106990814 \t val loss 0.027627620846033096\n",
      "\n",
      " EPOCH 109/500 \t train loss 0.03295127674937248 \t val loss 0.02652977965772152\n",
      "\n",
      " EPOCH 110/500 \t train loss 0.03275704011321068 \t val loss 0.026816492900252342\n",
      "\n",
      " EPOCH 111/500 \t train loss 0.032102178782224655 \t val loss 0.026102105155587196\n",
      "\n",
      " EPOCH 112/500 \t train loss 0.03184587135910988 \t val loss 0.026403076946735382\n",
      "\n",
      " EPOCH 113/500 \t train loss 0.03146883100271225 \t val loss 0.025716440752148628\n",
      "\n",
      " EPOCH 114/500 \t train loss 0.030919237062335014 \t val loss 0.02601729892194271\n",
      "\n",
      " EPOCH 115/500 \t train loss 0.03069661743938923 \t val loss 0.02516358532011509\n",
      "\n",
      " EPOCH 116/500 \t train loss 0.030459359288215637 \t val loss 0.024625081568956375\n",
      "\n",
      " EPOCH 117/500 \t train loss 0.030382923781871796 \t val loss 0.02475985325872898\n",
      "\n",
      " EPOCH 118/500 \t train loss 0.029926801100373268 \t val loss 0.024422112852334976\n",
      "\n",
      " EPOCH 119/500 \t train loss 0.0294613316655159 \t val loss 0.024635324254631996\n",
      "\n",
      " EPOCH 120/500 \t train loss 0.02952256053686142 \t val loss 0.02413238398730755\n",
      "\n",
      " EPOCH 121/500 \t train loss 0.0291547030210495 \t val loss 0.024069933220744133\n",
      "\n",
      " EPOCH 122/500 \t train loss 0.02865016460418701 \t val loss 0.02364489436149597\n",
      "\n",
      " EPOCH 123/500 \t train loss 0.02852047048509121 \t val loss 0.023611310869455338\n",
      "\n",
      " EPOCH 124/500 \t train loss 0.028673825785517693 \t val loss 0.023846497759222984\n",
      "\n",
      " EPOCH 125/500 \t train loss 0.027999602258205414 \t val loss 0.022680869325995445\n",
      "\n",
      " EPOCH 126/500 \t train loss 0.027736561372876167 \t val loss 0.02325250580906868\n",
      "\n",
      " EPOCH 127/500 \t train loss 0.027623703703284264 \t val loss 0.022604193538427353\n",
      "\n",
      " EPOCH 128/500 \t train loss 0.02730058692395687 \t val loss 0.02212354727089405\n",
      "\n",
      " EPOCH 129/500 \t train loss 0.027137555181980133 \t val loss 0.022063573822379112\n",
      "\n",
      " EPOCH 130/500 \t train loss 0.026915326714515686 \t val loss 0.022125791758298874\n",
      "\n",
      " EPOCH 131/500 \t train loss 0.026798376813530922 \t val loss 0.02242857590317726\n",
      "\n",
      " EPOCH 132/500 \t train loss 0.02636300027370453 \t val loss 0.022105999290943146\n",
      "\n",
      " EPOCH 133/500 \t train loss 0.02629636786878109 \t val loss 0.02133806422352791\n",
      "\n",
      " EPOCH 134/500 \t train loss 0.02624606154859066 \t val loss 0.021854164078831673\n",
      "\n",
      " EPOCH 135/500 \t train loss 0.026018457487225533 \t val loss 0.02166067436337471\n",
      "\n",
      " EPOCH 136/500 \t train loss 0.02579222060739994 \t val loss 0.02135186456143856\n",
      "\n",
      " EPOCH 137/500 \t train loss 0.025457551702857018 \t val loss 0.02109268307685852\n",
      "\n",
      " EPOCH 138/500 \t train loss 0.025250939652323723 \t val loss 0.020653294399380684\n",
      "\n",
      " EPOCH 139/500 \t train loss 0.025220222771167755 \t val loss 0.02054016850888729\n",
      "\n",
      " EPOCH 140/500 \t train loss 0.02515842765569687 \t val loss 0.02115304209291935\n",
      "\n",
      " EPOCH 141/500 \t train loss 0.024798357859253883 \t val loss 0.020274654030799866\n",
      "\n",
      " EPOCH 142/500 \t train loss 0.02465727925300598 \t val loss 0.0205690860748291\n",
      "\n",
      " EPOCH 143/500 \t train loss 0.024480119347572327 \t val loss 0.020381614565849304\n",
      "\n",
      " EPOCH 144/500 \t train loss 0.024514244869351387 \t val loss 0.020364798605442047\n",
      "\n",
      " EPOCH 145/500 \t train loss 0.024219363927841187 \t val loss 0.020420482382178307\n",
      "\n",
      " EPOCH 146/500 \t train loss 0.02418224699795246 \t val loss 0.020165827125310898\n",
      "\n",
      " EPOCH 147/500 \t train loss 0.023838059976696968 \t val loss 0.019865674898028374\n",
      "\n",
      " EPOCH 148/500 \t train loss 0.023701710626482964 \t val loss 0.019589634612202644\n",
      "\n",
      " EPOCH 149/500 \t train loss 0.023605801165103912 \t val loss 0.019601866602897644\n",
      "\n",
      " EPOCH 150/500 \t train loss 0.023448020219802856 \t val loss 0.019583364948630333\n",
      "\n",
      " EPOCH 151/500 \t train loss 0.02344328723847866 \t val loss 0.01990068145096302\n",
      "\n",
      " EPOCH 152/500 \t train loss 0.02320847101509571 \t val loss 0.01932627521455288\n",
      "\n",
      " EPOCH 153/500 \t train loss 0.023120418190956116 \t val loss 0.01939832977950573\n",
      "\n",
      " EPOCH 154/500 \t train loss 0.023047812283039093 \t val loss 0.01920614205300808\n",
      "\n",
      " EPOCH 155/500 \t train loss 0.023238396272063255 \t val loss 0.01951221562922001\n",
      "\n",
      " EPOCH 156/500 \t train loss 0.02289893664419651 \t val loss 0.018877625465393066\n",
      "\n",
      " EPOCH 157/500 \t train loss 0.022635146975517273 \t val loss 0.01886468566954136\n",
      "\n",
      " EPOCH 158/500 \t train loss 0.022459939122200012 \t val loss 0.01888243295252323\n",
      "\n",
      " EPOCH 159/500 \t train loss 0.02255435287952423 \t val loss 0.01874283328652382\n",
      "\n",
      " EPOCH 160/500 \t train loss 0.022294558584690094 \t val loss 0.01876045949757099\n",
      "\n",
      " EPOCH 161/500 \t train loss 0.022229133173823357 \t val loss 0.018621252849698067\n",
      "\n",
      " EPOCH 162/500 \t train loss 0.022184692323207855 \t val loss 0.01852327026426792\n",
      "\n",
      " EPOCH 163/500 \t train loss 0.02197949029505253 \t val loss 0.01878439448773861\n",
      "\n",
      " EPOCH 164/500 \t train loss 0.022038327530026436 \t val loss 0.018425310030579567\n",
      "\n",
      " EPOCH 165/500 \t train loss 0.021732710301876068 \t val loss 0.01833713985979557\n",
      "\n",
      " EPOCH 166/500 \t train loss 0.021763332188129425 \t val loss 0.018877165392041206\n",
      "\n",
      " EPOCH 167/500 \t train loss 0.021584367379546165 \t val loss 0.018286207690835\n",
      "\n",
      " EPOCH 168/500 \t train loss 0.021418968215584755 \t val loss 0.01816108077764511\n",
      "\n",
      " EPOCH 169/500 \t train loss 0.021361522376537323 \t val loss 0.018240218982100487\n",
      "\n",
      " EPOCH 170/500 \t train loss 0.021465063095092773 \t val loss 0.017779242247343063\n",
      "\n",
      " EPOCH 171/500 \t train loss 0.021192356944084167 \t val loss 0.018083298578858376\n",
      "\n",
      " EPOCH 172/500 \t train loss 0.021161368116736412 \t val loss 0.01787475124001503\n",
      "\n",
      " EPOCH 173/500 \t train loss 0.02105467952787876 \t val loss 0.01769368164241314\n",
      "\n",
      " EPOCH 174/500 \t train loss 0.02100815810263157 \t val loss 0.01768358051776886\n",
      "\n",
      " EPOCH 175/500 \t train loss 0.020878121256828308 \t val loss 0.0174726415425539\n",
      "\n",
      " EPOCH 176/500 \t train loss 0.02074389159679413 \t val loss 0.01761035993695259\n",
      "\n",
      " EPOCH 177/500 \t train loss 0.020694103091955185 \t val loss 0.01762428879737854\n",
      "\n",
      " EPOCH 178/500 \t train loss 0.020585542544722557 \t val loss 0.017503825947642326\n",
      "\n",
      " EPOCH 179/500 \t train loss 0.02074882574379444 \t val loss 0.01754407025873661\n",
      "\n",
      " EPOCH 180/500 \t train loss 0.02048252709209919 \t val loss 0.017462890595197678\n",
      "\n",
      " EPOCH 181/500 \t train loss 0.020522961392998695 \t val loss 0.01746896468102932\n",
      "\n",
      " EPOCH 182/500 \t train loss 0.02032141573727131 \t val loss 0.01726538874208927\n",
      "\n",
      " EPOCH 183/500 \t train loss 0.020323626697063446 \t val loss 0.01763930357992649\n",
      "\n",
      " EPOCH 184/500 \t train loss 0.020376835018396378 \t val loss 0.01708318665623665\n",
      "\n",
      " EPOCH 185/500 \t train loss 0.020194916054606438 \t val loss 0.01731407269835472\n",
      "\n",
      " EPOCH 186/500 \t train loss 0.020006390288472176 \t val loss 0.017359843477606773\n",
      "\n",
      " EPOCH 187/500 \t train loss 0.020038656890392303 \t val loss 0.017075277864933014\n",
      "\n",
      " EPOCH 188/500 \t train loss 0.01996872015297413 \t val loss 0.016995826736092567\n",
      "\n",
      " EPOCH 189/500 \t train loss 0.01980646513402462 \t val loss 0.016943182796239853\n",
      "\n",
      " EPOCH 190/500 \t train loss 0.019972078502178192 \t val loss 0.017061276361346245\n",
      "\n",
      " EPOCH 191/500 \t train loss 0.019802477210760117 \t val loss 0.01696668192744255\n",
      "\n",
      " EPOCH 192/500 \t train loss 0.019617443904280663 \t val loss 0.016996949911117554\n",
      "\n",
      " EPOCH 193/500 \t train loss 0.01954488269984722 \t val loss 0.016981903463602066\n",
      "\n",
      " EPOCH 194/500 \t train loss 0.019497880712151527 \t val loss 0.01678473874926567\n",
      "\n",
      " EPOCH 195/500 \t train loss 0.019468815997242928 \t val loss 0.01661681942641735\n",
      "\n",
      " EPOCH 196/500 \t train loss 0.019484873861074448 \t val loss 0.01671881042420864\n",
      "\n",
      " EPOCH 197/500 \t train loss 0.019421232864260674 \t val loss 0.016788899898529053\n",
      "\n",
      " EPOCH 198/500 \t train loss 0.01934531331062317 \t val loss 0.016514576971530914\n",
      "\n",
      " EPOCH 199/500 \t train loss 0.01937025599181652 \t val loss 0.01661708578467369\n",
      "\n",
      " EPOCH 200/500 \t train loss 0.019514895975589752 \t val loss 0.016489669680595398\n",
      "\n",
      " EPOCH 201/500 \t train loss 0.01908205635845661 \t val loss 0.016520323231816292\n",
      "\n",
      " EPOCH 202/500 \t train loss 0.019157538190484047 \t val loss 0.016302168369293213\n",
      "\n",
      " EPOCH 203/500 \t train loss 0.0190435778349638 \t val loss 0.016508422791957855\n",
      "\n",
      " EPOCH 204/500 \t train loss 0.019067728891968727 \t val loss 0.016319843009114265\n",
      "\n",
      " EPOCH 205/500 \t train loss 0.01900727115571499 \t val loss 0.016318799927830696\n",
      "\n",
      " EPOCH 206/500 \t train loss 0.018998809158802032 \t val loss 0.016443781554698944\n",
      "\n",
      " EPOCH 207/500 \t train loss 0.018815308809280396 \t val loss 0.016359087079763412\n",
      "\n",
      " EPOCH 208/500 \t train loss 0.018756423145532608 \t val loss 0.016166049987077713\n",
      "\n",
      " EPOCH 209/500 \t train loss 0.018731793388724327 \t val loss 0.016213025897741318\n",
      "\n",
      " EPOCH 210/500 \t train loss 0.018685711547732353 \t val loss 0.016473544761538506\n",
      "\n",
      " EPOCH 211/500 \t train loss 0.018738912418484688 \t val loss 0.016168901696801186\n",
      "\n",
      " EPOCH 212/500 \t train loss 0.01867770217359066 \t val loss 0.01599690318107605\n",
      "\n",
      " EPOCH 213/500 \t train loss 0.018603350967168808 \t val loss 0.016024624928832054\n",
      "\n",
      " EPOCH 214/500 \t train loss 0.01869223453104496 \t val loss 0.016151338815689087\n",
      "\n",
      " EPOCH 215/500 \t train loss 0.018580211326479912 \t val loss 0.016212159767746925\n",
      "\n",
      " EPOCH 216/500 \t train loss 0.018488051369786263 \t val loss 0.01596130058169365\n",
      "\n",
      " EPOCH 217/500 \t train loss 0.01826963573694229 \t val loss 0.0159219428896904\n",
      "\n",
      " EPOCH 218/500 \t train loss 0.01841512881219387 \t val loss 0.01597895659506321\n",
      "\n",
      " EPOCH 219/500 \t train loss 0.018361391499638557 \t val loss 0.01596321538090706\n",
      "\n",
      " EPOCH 220/500 \t train loss 0.018307795748114586 \t val loss 0.015890046954154968\n",
      "\n",
      " EPOCH 221/500 \t train loss 0.01822560653090477 \t val loss 0.015893956646323204\n",
      "\n",
      " EPOCH 222/500 \t train loss 0.018090469762682915 \t val loss 0.01582237146794796\n",
      "\n",
      " EPOCH 223/500 \t train loss 0.018259180709719658 \t val loss 0.015813691541552544\n",
      "\n",
      " EPOCH 224/500 \t train loss 0.0181832667440176 \t val loss 0.015893355011940002\n",
      "\n",
      " EPOCH 225/500 \t train loss 0.017955977469682693 \t val loss 0.015861252322793007\n",
      "\n",
      " EPOCH 226/500 \t train loss 0.017905501648783684 \t val loss 0.01572408340871334\n",
      "\n",
      " EPOCH 227/500 \t train loss 0.017867786809802055 \t val loss 0.015598715282976627\n",
      "\n",
      " EPOCH 228/500 \t train loss 0.017987046390771866 \t val loss 0.015692345798015594\n",
      "\n",
      " EPOCH 229/500 \t train loss 0.01777692697942257 \t val loss 0.01564275659620762\n",
      "\n",
      " EPOCH 230/500 \t train loss 0.017767423763871193 \t val loss 0.015603875741362572\n",
      "\n",
      " EPOCH 231/500 \t train loss 0.01777365617454052 \t val loss 0.015724826604127884\n",
      "\n",
      " EPOCH 232/500 \t train loss 0.01788788102567196 \t val loss 0.015530895441770554\n",
      "\n",
      " EPOCH 233/500 \t train loss 0.017758559435606003 \t val loss 0.015504872426390648\n",
      "\n",
      " EPOCH 234/500 \t train loss 0.017819801345467567 \t val loss 0.01576223224401474\n",
      "\n",
      " EPOCH 235/500 \t train loss 0.017729198560118675 \t val loss 0.015519179403781891\n",
      "\n",
      " EPOCH 236/500 \t train loss 0.017702465876936913 \t val loss 0.015676436945796013\n",
      "\n",
      " EPOCH 237/500 \t train loss 0.017496753484010696 \t val loss 0.01547200232744217\n",
      "\n",
      " EPOCH 238/500 \t train loss 0.01746477000415325 \t val loss 0.015495468862354755\n",
      "\n",
      " EPOCH 239/500 \t train loss 0.017531491816043854 \t val loss 0.015397188253700733\n",
      "\n",
      " EPOCH 240/500 \t train loss 0.017426278442144394 \t val loss 0.015351824462413788\n",
      "\n",
      " EPOCH 241/500 \t train loss 0.017369180917739868 \t val loss 0.015379461459815502\n",
      "\n",
      " EPOCH 242/500 \t train loss 0.01753005012869835 \t val loss 0.015409569256007671\n",
      "\n",
      " EPOCH 243/500 \t train loss 0.01756564900279045 \t val loss 0.015265033580362797\n",
      "\n",
      " EPOCH 244/500 \t train loss 0.017486443743109703 \t val loss 0.015362587757408619\n",
      "\n",
      " EPOCH 245/500 \t train loss 0.017356757074594498 \t val loss 0.015360494144260883\n",
      "\n",
      " EPOCH 246/500 \t train loss 0.017444131895899773 \t val loss 0.015196049585938454\n",
      "\n",
      " EPOCH 247/500 \t train loss 0.017317907884716988 \t val loss 0.015139536932110786\n",
      "\n",
      " EPOCH 248/500 \t train loss 0.01724078133702278 \t val loss 0.015154590830206871\n",
      "\n",
      " EPOCH 249/500 \t train loss 0.017262117937207222 \t val loss 0.015292219817638397\n",
      "\n",
      " EPOCH 250/500 \t train loss 0.017164763063192368 \t val loss 0.015159384347498417\n",
      "\n",
      " EPOCH 251/500 \t train loss 0.01712763123214245 \t val loss 0.015095776878297329\n",
      "\n",
      " EPOCH 252/500 \t train loss 0.017035087570548058 \t val loss 0.015249010175466537\n",
      "\n",
      " EPOCH 253/500 \t train loss 0.017072338610887527 \t val loss 0.015165060758590698\n",
      "\n",
      " EPOCH 254/500 \t train loss 0.016939209774136543 \t val loss 0.01544471736997366\n",
      "\n",
      " EPOCH 255/500 \t train loss 0.017017120495438576 \t val loss 0.015129920095205307\n",
      "\n",
      " EPOCH 256/500 \t train loss 0.017052380368113518 \t val loss 0.014990939758718014\n",
      "\n",
      " EPOCH 257/500 \t train loss 0.017038090154528618 \t val loss 0.015069322660565376\n",
      "\n",
      " EPOCH 258/500 \t train loss 0.01700751669704914 \t val loss 0.015051687136292458\n",
      "\n",
      " EPOCH 259/500 \t train loss 0.016838327050209045 \t val loss 0.015203705988824368\n",
      "\n",
      " EPOCH 260/500 \t train loss 0.016872169449925423 \t val loss 0.015014062635600567\n",
      "\n",
      " EPOCH 261/500 \t train loss 0.01686917245388031 \t val loss 0.014891186729073524\n",
      "\n",
      " EPOCH 262/500 \t train loss 0.016887472942471504 \t val loss 0.01492916326969862\n",
      "\n",
      " EPOCH 263/500 \t train loss 0.01670183800160885 \t val loss 0.015027613379061222\n",
      "\n",
      " EPOCH 264/500 \t train loss 0.01674620993435383 \t val loss 0.015011919662356377\n",
      "\n",
      " EPOCH 265/500 \t train loss 0.017038138583302498 \t val loss 0.01486721821129322\n",
      "\n",
      " EPOCH 266/500 \t train loss 0.016725406050682068 \t val loss 0.014880078844726086\n",
      "\n",
      " EPOCH 267/500 \t train loss 0.016683971509337425 \t val loss 0.014946486800909042\n",
      "\n",
      " EPOCH 268/500 \t train loss 0.016607582569122314 \t val loss 0.014786772429943085\n",
      "\n",
      " EPOCH 269/500 \t train loss 0.0167167279869318 \t val loss 0.014957208186388016\n",
      "\n",
      " EPOCH 270/500 \t train loss 0.01673709787428379 \t val loss 0.01497188862413168\n",
      "\n",
      " EPOCH 271/500 \t train loss 0.016577264294028282 \t val loss 0.01492704451084137\n",
      "\n",
      " EPOCH 272/500 \t train loss 0.01641751080751419 \t val loss 0.014768936671316624\n",
      "\n",
      " EPOCH 273/500 \t train loss 0.016496486961841583 \t val loss 0.014827421866357327\n",
      "\n",
      " EPOCH 274/500 \t train loss 0.016587167978286743 \t val loss 0.014697005972266197\n",
      "\n",
      " EPOCH 275/500 \t train loss 0.016446558758616447 \t val loss 0.014789472334086895\n",
      "\n",
      " EPOCH 276/500 \t train loss 0.01645011082291603 \t val loss 0.014767393469810486\n",
      "\n",
      " EPOCH 277/500 \t train loss 0.01640835963189602 \t val loss 0.014735755510628223\n",
      "\n",
      " EPOCH 278/500 \t train loss 0.016515126451849937 \t val loss 0.014700105413794518\n",
      "\n",
      " EPOCH 279/500 \t train loss 0.016572946682572365 \t val loss 0.014730434864759445\n",
      "\n",
      " EPOCH 280/500 \t train loss 0.016316920518875122 \t val loss 0.014635998755693436\n",
      "\n",
      " EPOCH 281/500 \t train loss 0.016315439715981483 \t val loss 0.014752276241779327\n",
      "\n",
      " EPOCH 282/500 \t train loss 0.016334248706698418 \t val loss 0.014666714705526829\n",
      "\n",
      " EPOCH 283/500 \t train loss 0.01639861799776554 \t val loss 0.014761089347302914\n",
      "\n",
      " EPOCH 284/500 \t train loss 0.01616213470697403 \t val loss 0.014605122618377209\n",
      "\n",
      " EPOCH 285/500 \t train loss 0.01631850004196167 \t val loss 0.014727868139743805\n",
      "\n",
      " EPOCH 286/500 \t train loss 0.01621898077428341 \t val loss 0.014635041356086731\n",
      "\n",
      " EPOCH 287/500 \t train loss 0.016139203682541847 \t val loss 0.01464860886335373\n",
      "\n",
      " EPOCH 288/500 \t train loss 0.016110533848404884 \t val loss 0.014553846791386604\n",
      "\n",
      " EPOCH 289/500 \t train loss 0.01611344702541828 \t val loss 0.014500218443572521\n",
      "\n",
      " EPOCH 290/500 \t train loss 0.016184797510504723 \t val loss 0.014598852954804897\n",
      "\n",
      " EPOCH 291/500 \t train loss 0.01611977256834507 \t val loss 0.014725648798048496\n",
      "\n",
      " EPOCH 292/500 \t train loss 0.01601649820804596 \t val loss 0.01455235481262207\n",
      "\n",
      " EPOCH 293/500 \t train loss 0.01594187505543232 \t val loss 0.014561719261109829\n",
      "\n",
      " EPOCH 294/500 \t train loss 0.016009649261832237 \t val loss 0.014392581768333912\n",
      "\n",
      " EPOCH 295/500 \t train loss 0.015945691615343094 \t val loss 0.014523151330649853\n",
      "\n",
      " EPOCH 296/500 \t train loss 0.01609623059630394 \t val loss 0.01454475149512291\n",
      "\n",
      " EPOCH 297/500 \t train loss 0.016166280955076218 \t val loss 0.014447025023400784\n",
      "\n",
      " EPOCH 298/500 \t train loss 0.01593528501689434 \t val loss 0.014510500244796276\n",
      "\n",
      " EPOCH 299/500 \t train loss 0.01589152030646801 \t val loss 0.014500885270535946\n",
      "\n",
      " EPOCH 300/500 \t train loss 0.01588420383632183 \t val loss 0.01447196863591671\n",
      "\n",
      " EPOCH 301/500 \t train loss 0.015895221382379532 \t val loss 0.01444933656603098\n",
      "\n",
      " EPOCH 302/500 \t train loss 0.01602615974843502 \t val loss 0.014281244948506355\n",
      "\n",
      " EPOCH 303/500 \t train loss 0.01592094637453556 \t val loss 0.014247220940887928\n",
      "\n",
      " EPOCH 304/500 \t train loss 0.01586758717894554 \t val loss 0.014399681240320206\n",
      "\n",
      " EPOCH 305/500 \t train loss 0.01574072428047657 \t val loss 0.014413631521165371\n",
      "\n",
      " EPOCH 306/500 \t train loss 0.01581818424165249 \t val loss 0.014385661110281944\n",
      "\n",
      " EPOCH 307/500 \t train loss 0.015669601038098335 \t val loss 0.01447864156216383\n",
      "\n",
      " EPOCH 308/500 \t train loss 0.01574113592505455 \t val loss 0.014418788254261017\n",
      "\n",
      " EPOCH 309/500 \t train loss 0.0157259963452816 \t val loss 0.014358078129589558\n",
      "\n",
      " EPOCH 310/500 \t train loss 0.015681227669119835 \t val loss 0.014413734897971153\n",
      "\n",
      " EPOCH 311/500 \t train loss 0.015603476203978062 \t val loss 0.01421361230313778\n",
      "\n",
      " EPOCH 312/500 \t train loss 0.01561039686203003 \t val loss 0.014419583603739738\n",
      "\n",
      " EPOCH 313/500 \t train loss 0.01563461683690548 \t val loss 0.014349165372550488\n",
      "\n",
      " EPOCH 314/500 \t train loss 0.01562301442027092 \t val loss 0.014208423905074596\n",
      "\n",
      " EPOCH 315/500 \t train loss 0.015598955564200878 \t val loss 0.014163008891046047\n",
      "\n",
      " EPOCH 316/500 \t train loss 0.015574735589325428 \t val loss 0.014396822080016136\n",
      "\n",
      " EPOCH 317/500 \t train loss 0.015559707768261433 \t val loss 0.01437534298747778\n",
      "\n",
      " EPOCH 318/500 \t train loss 0.015564550645649433 \t val loss 0.014150048606097698\n",
      "\n",
      " EPOCH 319/500 \t train loss 0.015507002361118793 \t val loss 0.014162871055305004\n",
      "\n",
      " EPOCH 320/500 \t train loss 0.015425872057676315 \t val loss 0.014175862073898315\n",
      "\n",
      " EPOCH 321/500 \t train loss 0.015488550998270512 \t val loss 0.014182793907821178\n",
      "\n",
      " EPOCH 322/500 \t train loss 0.015404894948005676 \t val loss 0.013985543511807919\n",
      "\n",
      " EPOCH 323/500 \t train loss 0.015414510853588581 \t val loss 0.014058616012334824\n",
      "\n",
      " EPOCH 324/500 \t train loss 0.015404258854687214 \t val loss 0.014210634864866734\n",
      "\n",
      " EPOCH 325/500 \t train loss 0.015369691886007786 \t val loss 0.014217752031981945\n",
      "\n",
      " EPOCH 326/500 \t train loss 0.015279174782335758 \t val loss 0.014167959801852703\n",
      "\n",
      " EPOCH 327/500 \t train loss 0.015457174740731716 \t val loss 0.014096342027187347\n",
      "\n",
      " EPOCH 328/500 \t train loss 0.015340480022132397 \t val loss 0.014189147390425205\n",
      "\n",
      " EPOCH 329/500 \t train loss 0.01532154530286789 \t val loss 0.014076913706958294\n",
      "\n",
      " EPOCH 330/500 \t train loss 0.015358497388660908 \t val loss 0.014060304500162601\n",
      "\n",
      " EPOCH 331/500 \t train loss 0.015282082371413708 \t val loss 0.014006203971803188\n",
      "\n",
      " EPOCH 332/500 \t train loss 0.01530249323695898 \t val loss 0.014183878898620605\n",
      "\n",
      " EPOCH 333/500 \t train loss 0.015228363685309887 \t val loss 0.014173847623169422\n",
      "\n",
      " EPOCH 334/500 \t train loss 0.015219288878142834 \t val loss 0.014218398369848728\n",
      "\n",
      " EPOCH 335/500 \t train loss 0.015247843228280544 \t val loss 0.01389366202056408\n",
      "\n",
      " EPOCH 336/500 \t train loss 0.015304524451494217 \t val loss 0.013984170742332935\n",
      "\n",
      " EPOCH 337/500 \t train loss 0.015067419968545437 \t val loss 0.014093698002398014\n",
      "\n",
      " EPOCH 338/500 \t train loss 0.015065285377204418 \t val loss 0.014086119830608368\n",
      "\n",
      " EPOCH 339/500 \t train loss 0.015141886658966541 \t val loss 0.013888210989534855\n",
      "\n",
      " EPOCH 340/500 \t train loss 0.01511265616863966 \t val loss 0.014060469344258308\n",
      "\n",
      " EPOCH 341/500 \t train loss 0.015208855271339417 \t val loss 0.013790754601359367\n",
      "\n",
      " EPOCH 342/500 \t train loss 0.015171968378126621 \t val loss 0.01378401555120945\n",
      "\n",
      " EPOCH 343/500 \t train loss 0.015017427504062653 \t val loss 0.013966856524348259\n",
      "\n",
      " EPOCH 344/500 \t train loss 0.015138312242925167 \t val loss 0.013902521692216396\n",
      "\n",
      " EPOCH 345/500 \t train loss 0.014996719546616077 \t val loss 0.013822395354509354\n",
      "\n",
      " EPOCH 346/500 \t train loss 0.014925021678209305 \t val loss 0.013844928704202175\n",
      "\n",
      " EPOCH 347/500 \t train loss 0.014980685897171497 \t val loss 0.013977672904729843\n",
      "\n",
      " EPOCH 348/500 \t train loss 0.01504141092300415 \t val loss 0.013881142251193523\n",
      "\n",
      " EPOCH 349/500 \t train loss 0.01505973469465971 \t val loss 0.013763384893536568\n",
      "\n",
      " EPOCH 350/500 \t train loss 0.014871328137814999 \t val loss 0.013797292485833168\n",
      "\n",
      " EPOCH 351/500 \t train loss 0.014933754689991474 \t val loss 0.013950986787676811\n",
      "\n",
      " EPOCH 352/500 \t train loss 0.014803487807512283 \t val loss 0.014003574848175049\n",
      "\n",
      " EPOCH 353/500 \t train loss 0.014978308230638504 \t val loss 0.013939309865236282\n",
      "\n",
      " EPOCH 354/500 \t train loss 0.01474419329315424 \t val loss 0.013700123876333237\n",
      "\n",
      " EPOCH 355/500 \t train loss 0.014911897480487823 \t val loss 0.01380682922899723\n",
      "\n",
      " EPOCH 356/500 \t train loss 0.014819655567407608 \t val loss 0.01374147366732359\n",
      "\n",
      " EPOCH 357/500 \t train loss 0.014700647443532944 \t val loss 0.013961127027869225\n",
      "\n",
      " EPOCH 358/500 \t train loss 0.014710705727338791 \t val loss 0.013887893408536911\n",
      "\n",
      " EPOCH 359/500 \t train loss 0.01475775707513094 \t val loss 0.013828023336827755\n",
      "\n",
      " EPOCH 360/500 \t train loss 0.014724635519087315 \t val loss 0.013669423758983612\n",
      "\n",
      " EPOCH 361/500 \t train loss 0.014758698642253876 \t val loss 0.013741301372647285\n",
      "\n",
      " EPOCH 362/500 \t train loss 0.014663581736385822 \t val loss 0.013595469295978546\n",
      "\n",
      " EPOCH 363/500 \t train loss 0.014762322418391705 \t val loss 0.013916938565671444\n",
      "\n",
      " EPOCH 364/500 \t train loss 0.014730948023498058 \t val loss 0.013738097622990608\n",
      "\n",
      " EPOCH 365/500 \t train loss 0.014714889228343964 \t val loss 0.013884441927075386\n",
      "\n",
      " EPOCH 366/500 \t train loss 0.014846247620880604 \t val loss 0.013631075620651245\n",
      "\n",
      " EPOCH 367/500 \t train loss 0.014724940061569214 \t val loss 0.013865433633327484\n",
      "\n",
      " EPOCH 368/500 \t train loss 0.014628749340772629 \t val loss 0.013698654249310493\n",
      "\n",
      " EPOCH 369/500 \t train loss 0.014613310806453228 \t val loss 0.013696414418518543\n",
      "\n",
      " EPOCH 370/500 \t train loss 0.014658797532320023 \t val loss 0.013562693260610104\n",
      "\n",
      " EPOCH 371/500 \t train loss 0.014744245447218418 \t val loss 0.013689533807337284\n",
      "\n",
      " EPOCH 372/500 \t train loss 0.014631460420787334 \t val loss 0.013598574325442314\n",
      "\n",
      " EPOCH 373/500 \t train loss 0.014637273736298084 \t val loss 0.013912104070186615\n",
      "\n",
      " EPOCH 374/500 \t train loss 0.014530128799378872 \t val loss 0.013808181509375572\n",
      "\n",
      " EPOCH 375/500 \t train loss 0.014722918160259724 \t val loss 0.013640484772622585\n",
      "\n",
      " EPOCH 376/500 \t train loss 0.014686963520944118 \t val loss 0.013446647673845291\n",
      "\n",
      " EPOCH 377/500 \t train loss 0.014516308903694153 \t val loss 0.013632187619805336\n",
      "\n",
      " EPOCH 378/500 \t train loss 0.014698315411806107 \t val loss 0.013612800277769566\n",
      "\n",
      " EPOCH 379/500 \t train loss 0.014529973268508911 \t val loss 0.013532341457903385\n",
      "\n",
      " EPOCH 380/500 \t train loss 0.01451626792550087 \t val loss 0.013804718852043152\n",
      "\n",
      " EPOCH 381/500 \t train loss 0.01480922568589449 \t val loss 0.013621983118355274\n",
      "\n",
      " EPOCH 382/500 \t train loss 0.014474607072770596 \t val loss 0.013683339580893517\n",
      "\n",
      " EPOCH 383/500 \t train loss 0.014424757100641727 \t val loss 0.013600334525108337\n",
      "\n",
      " EPOCH 384/500 \t train loss 0.014382039196789265 \t val loss 0.013474121689796448\n",
      "\n",
      " EPOCH 385/500 \t train loss 0.014432589523494244 \t val loss 0.013513945043087006\n",
      "\n",
      " EPOCH 386/500 \t train loss 0.014342845417559147 \t val loss 0.01358762290328741\n",
      "\n",
      " EPOCH 387/500 \t train loss 0.014475091360509396 \t val loss 0.013472888618707657\n",
      "\n",
      " EPOCH 388/500 \t train loss 0.01435481384396553 \t val loss 0.013549316674470901\n",
      "\n",
      " EPOCH 389/500 \t train loss 0.014339350163936615 \t val loss 0.013707548379898071\n",
      "\n",
      " EPOCH 390/500 \t train loss 0.014311820268630981 \t val loss 0.013486267998814583\n",
      "\n",
      " EPOCH 391/500 \t train loss 0.014340442605316639 \t val loss 0.013528233394026756\n",
      "\n",
      " EPOCH 392/500 \t train loss 0.014407612383365631 \t val loss 0.013555931858718395\n",
      "\n",
      " EPOCH 393/500 \t train loss 0.014267408289015293 \t val loss 0.013775057159364223\n",
      "\n",
      " EPOCH 394/500 \t train loss 0.014319182373583317 \t val loss 0.013511651195585728\n",
      "\n",
      " EPOCH 395/500 \t train loss 0.014407016336917877 \t val loss 0.013338638469576836\n",
      "\n",
      " EPOCH 396/500 \t train loss 0.014112569391727448 \t val loss 0.013446290977299213\n",
      "\n",
      " EPOCH 397/500 \t train loss 0.014231610111892223 \t val loss 0.013621649704873562\n",
      "\n",
      " EPOCH 398/500 \t train loss 0.014201355166733265 \t val loss 0.013717140071094036\n",
      "\n",
      " EPOCH 399/500 \t train loss 0.014118448831140995 \t val loss 0.013620587065815926\n",
      "\n",
      " EPOCH 400/500 \t train loss 0.01421330962330103 \t val loss 0.0134620675817132\n",
      "\n",
      " EPOCH 401/500 \t train loss 0.014193873852491379 \t val loss 0.013319207355380058\n",
      "\n",
      " EPOCH 402/500 \t train loss 0.014125690795481205 \t val loss 0.013329753652215004\n",
      "\n",
      " EPOCH 403/500 \t train loss 0.014083598740398884 \t val loss 0.013394991867244244\n",
      "\n",
      " EPOCH 404/500 \t train loss 0.014051674865186214 \t val loss 0.013844841159880161\n",
      "\n",
      " EPOCH 405/500 \t train loss 0.014114681631326675 \t val loss 0.013495850376784801\n",
      "\n",
      " EPOCH 406/500 \t train loss 0.014105054549872875 \t val loss 0.0132552245631814\n",
      "\n",
      " EPOCH 407/500 \t train loss 0.014186584390699863 \t val loss 0.013630678877234459\n",
      "\n",
      " EPOCH 408/500 \t train loss 0.014054075814783573 \t val loss 0.013562137261033058\n",
      "\n",
      " EPOCH 409/500 \t train loss 0.014134681783616543 \t val loss 0.013407914899289608\n",
      "\n",
      " EPOCH 410/500 \t train loss 0.014051716774702072 \t val loss 0.013418118469417095\n",
      "\n",
      " EPOCH 411/500 \t train loss 0.014124940149486065 \t val loss 0.013465394265949726\n",
      "\n",
      " EPOCH 412/500 \t train loss 0.01408974826335907 \t val loss 0.013318980112671852\n",
      "\n",
      " EPOCH 413/500 \t train loss 0.014126169495284557 \t val loss 0.013789854943752289\n",
      "\n",
      " EPOCH 414/500 \t train loss 0.013979711569845676 \t val loss 0.013442238792777061\n",
      "\n",
      " EPOCH 415/500 \t train loss 0.01399555429816246 \t val loss 0.013474230654537678\n",
      "\n",
      " EPOCH 416/500 \t train loss 0.01404906902462244 \t val loss 0.013188065029680729\n",
      "\n",
      " EPOCH 417/500 \t train loss 0.01405525952577591 \t val loss 0.013318167068064213\n",
      "\n",
      " EPOCH 418/500 \t train loss 0.013947960920631886 \t val loss 0.013376140035688877\n",
      "\n",
      " EPOCH 419/500 \t train loss 0.013888035900890827 \t val loss 0.013292218558490276\n",
      "\n",
      " EPOCH 420/500 \t train loss 0.013944883830845356 \t val loss 0.013407164253294468\n",
      "\n",
      " EPOCH 421/500 \t train loss 0.013867150992155075 \t val loss 0.013325116597115993\n",
      "\n",
      " EPOCH 422/500 \t train loss 0.014002167619764805 \t val loss 0.013383514247834682\n",
      "\n",
      " EPOCH 423/500 \t train loss 0.013956722803413868 \t val loss 0.01351896021515131\n",
      "\n",
      " EPOCH 424/500 \t train loss 0.014238395728170872 \t val loss 0.013207735493779182\n",
      "\n",
      " EPOCH 425/500 \t train loss 0.01394967082887888 \t val loss 0.0133173493668437\n",
      "\n",
      " EPOCH 426/500 \t train loss 0.01401492115110159 \t val loss 0.013524065725505352\n",
      "\n",
      " EPOCH 427/500 \t train loss 0.013980083167552948 \t val loss 0.013256349600851536\n",
      "\n",
      " EPOCH 428/500 \t train loss 0.013837804086506367 \t val loss 0.013324175961315632\n",
      "\n",
      " EPOCH 429/500 \t train loss 0.013962026685476303 \t val loss 0.013464655727148056\n",
      "\n",
      " EPOCH 430/500 \t train loss 0.013953265734016895 \t val loss 0.013203722424805164\n",
      "\n",
      " EPOCH 431/500 \t train loss 0.0138450488448143 \t val loss 0.013249166309833527\n",
      "\n",
      " EPOCH 432/500 \t train loss 0.013908821158111095 \t val loss 0.013227662071585655\n",
      "\n",
      " EPOCH 433/500 \t train loss 0.01385385263711214 \t val loss 0.013312237337231636\n",
      "\n",
      " EPOCH 434/500 \t train loss 0.013738171197474003 \t val loss 0.013480788096785545\n",
      "\n",
      " EPOCH 435/500 \t train loss 0.01381326001137495 \t val loss 0.013387213461101055\n",
      "\n",
      " EPOCH 436/500 \t train loss 0.013851885683834553 \t val loss 0.013355578295886517\n",
      "\n",
      " EPOCH 437/500 \t train loss 0.013690813444554806 \t val loss 0.01327065471559763\n",
      "\n",
      " EPOCH 438/500 \t train loss 0.013725095428526402 \t val loss 0.013341747224330902\n",
      "\n",
      " EPOCH 439/500 \t train loss 0.013800770044326782 \t val loss 0.013268919661641121\n",
      "\n",
      " EPOCH 440/500 \t train loss 0.013829228468239307 \t val loss 0.013276594690978527\n",
      "\n",
      " EPOCH 441/500 \t train loss 0.01368702668696642 \t val loss 0.013253116980195045\n",
      "\n",
      " EPOCH 442/500 \t train loss 0.013766380958259106 \t val loss 0.01318995002657175\n",
      "\n",
      " EPOCH 443/500 \t train loss 0.013822920620441437 \t val loss 0.013385954312980175\n",
      "\n",
      " EPOCH 444/500 \t train loss 0.01366313174366951 \t val loss 0.01316048577427864\n",
      "\n",
      " EPOCH 445/500 \t train loss 0.01373815257102251 \t val loss 0.013184797018766403\n",
      "\n",
      " EPOCH 446/500 \t train loss 0.013595432974398136 \t val loss 0.013329516164958477\n",
      "\n",
      " EPOCH 447/500 \t train loss 0.013782617636024952 \t val loss 0.013169553130865097\n",
      "\n",
      " EPOCH 448/500 \t train loss 0.013721783645451069 \t val loss 0.013262651860713959\n",
      "\n",
      " EPOCH 449/500 \t train loss 0.013698793016374111 \t val loss 0.013176879845559597\n",
      "\n",
      " EPOCH 450/500 \t train loss 0.013677635230123997 \t val loss 0.013234211131930351\n",
      "\n",
      " EPOCH 451/500 \t train loss 0.013556896708905697 \t val loss 0.013433216139674187\n",
      "\n",
      " EPOCH 452/500 \t train loss 0.013704951852560043 \t val loss 0.013357918709516525\n",
      "\n",
      " EPOCH 453/500 \t train loss 0.013724773190915585 \t val loss 0.013231405057013035\n",
      "\n",
      " EPOCH 454/500 \t train loss 0.013650071807205677 \t val loss 0.013345526531338692\n",
      "\n",
      " EPOCH 455/500 \t train loss 0.013638518750667572 \t val loss 0.013225778006017208\n",
      "\n",
      " EPOCH 456/500 \t train loss 0.013750414364039898 \t val loss 0.013085504062473774\n",
      "\n",
      " EPOCH 457/500 \t train loss 0.013565413653850555 \t val loss 0.013056932017207146\n",
      "\n",
      " EPOCH 458/500 \t train loss 0.013639397919178009 \t val loss 0.013246823102235794\n",
      "\n",
      " EPOCH 459/500 \t train loss 0.013625978492200375 \t val loss 0.013282244093716145\n",
      "\n",
      " EPOCH 460/500 \t train loss 0.013527944684028625 \t val loss 0.013170158490538597\n",
      "\n",
      " EPOCH 461/500 \t train loss 0.01358894631266594 \t val loss 0.013146334327757359\n",
      "\n",
      " EPOCH 462/500 \t train loss 0.01352077629417181 \t val loss 0.013197913765907288\n",
      "\n",
      " EPOCH 463/500 \t train loss 0.013611077331006527 \t val loss 0.01321400050073862\n",
      "\n",
      " EPOCH 464/500 \t train loss 0.013477594591677189 \t val loss 0.012988554313778877\n",
      "\n",
      " EPOCH 465/500 \t train loss 0.01359559502452612 \t val loss 0.013380353339016438\n",
      "\n",
      " EPOCH 466/500 \t train loss 0.013628090731799603 \t val loss 0.013158532790839672\n",
      "\n",
      " EPOCH 467/500 \t train loss 0.013508240692317486 \t val loss 0.013191482983529568\n",
      "\n",
      " EPOCH 468/500 \t train loss 0.013395915739238262 \t val loss 0.013121671974658966\n",
      "\n",
      " EPOCH 469/500 \t train loss 0.013383760116994381 \t val loss 0.013184302486479282\n",
      "\n",
      " EPOCH 470/500 \t train loss 0.013423047959804535 \t val loss 0.013263714499771595\n",
      "\n",
      " EPOCH 471/500 \t train loss 0.013453926891088486 \t val loss 0.013018401339650154\n",
      "\n",
      " EPOCH 472/500 \t train loss 0.013451874256134033 \t val loss 0.013234086334705353\n",
      "\n",
      " EPOCH 473/500 \t train loss 0.01337403804063797 \t val loss 0.01317654736340046\n",
      "\n",
      " EPOCH 474/500 \t train loss 0.013339241035282612 \t val loss 0.013180251233279705\n",
      "\n",
      " EPOCH 475/500 \t train loss 0.013332091271877289 \t val loss 0.013335849158465862\n",
      "\n",
      " EPOCH 476/500 \t train loss 0.013356402516365051 \t val loss 0.013124712742865086\n",
      "\n",
      " EPOCH 477/500 \t train loss 0.013440622948110104 \t val loss 0.01300802081823349\n",
      "\n",
      " EPOCH 478/500 \t train loss 0.013231133110821247 \t val loss 0.013233402743935585\n",
      "\n",
      " EPOCH 479/500 \t train loss 0.013304452411830425 \t val loss 0.013132486492395401\n",
      "\n",
      " EPOCH 480/500 \t train loss 0.013394207693636417 \t val loss 0.013338319957256317\n",
      "\n",
      " EPOCH 481/500 \t train loss 0.013599246740341187 \t val loss 0.012926041148602962\n",
      "\n",
      " EPOCH 482/500 \t train loss 0.013347393833100796 \t val loss 0.013027438893914223\n",
      "\n",
      " EPOCH 483/500 \t train loss 0.013366248458623886 \t val loss 0.013145685195922852\n",
      "\n",
      " EPOCH 484/500 \t train loss 0.013244815170764923 \t val loss 0.013312263414263725\n",
      "\n",
      " EPOCH 485/500 \t train loss 0.013407029211521149 \t val loss 0.012876864522695541\n",
      "\n",
      " EPOCH 486/500 \t train loss 0.013277246616780758 \t val loss 0.013003821484744549\n",
      "\n",
      " EPOCH 487/500 \t train loss 0.013305614702403545 \t val loss 0.013099276460707188\n",
      "\n",
      " EPOCH 488/500 \t train loss 0.013258787803351879 \t val loss 0.013248602859675884\n",
      "\n",
      " EPOCH 489/500 \t train loss 0.013399559073150158 \t val loss 0.013216701336205006\n",
      "\n",
      " EPOCH 490/500 \t train loss 0.013550002127885818 \t val loss 0.012949406169354916\n",
      "\n",
      " EPOCH 491/500 \t train loss 0.013220385648310184 \t val loss 0.013043330051004887\n",
      "\n",
      " EPOCH 492/500 \t train loss 0.013358327560126781 \t val loss 0.013087878003716469\n",
      "\n",
      " EPOCH 493/500 \t train loss 0.013260939158499241 \t val loss 0.013088655658066273\n",
      "\n",
      " EPOCH 494/500 \t train loss 0.01319272443652153 \t val loss 0.013450565747916698\n",
      "\n",
      " EPOCH 495/500 \t train loss 0.01322502177208662 \t val loss 0.01316913217306137\n",
      "\n",
      " EPOCH 496/500 \t train loss 0.013208966702222824 \t val loss 0.012984387576580048\n",
      "\n",
      " EPOCH 497/500 \t train loss 0.01322055235505104 \t val loss 0.012930255383253098\n",
      "\n",
      " EPOCH 498/500 \t train loss 0.013143631629645824 \t val loss 0.012994149699807167\n",
      "\n",
      " EPOCH 499/500 \t train loss 0.01321303378790617 \t val loss 0.013120163232088089\n",
      "\n",
      " EPOCH 500/500 \t train loss 0.01319777499884367 \t val loss 0.013151265680789948\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 500\n",
    "diz_loss = {'train_loss':[],'val_loss':[]}\n",
    "for epoch in range(num_epochs):\n",
    "\ttrain_loss =train_epoch(encoder,decoder,device,train_loader,loss_fn,optim)\n",
    "\tval_loss = test_epoch(encoder,decoder,device,test_loader,loss_fn)\n",
    "\tprint('\\n EPOCH {}/{} \\t train loss {} \\t val loss {}'.format(epoch + 1, num_epochs,train_loss,val_loss))\n",
    "\tdiz_loss['train_loss'].append(train_loss)\n",
    "\tdiz_loss['val_loss'].append(val_loss)\n",
    "\n",
    "\tif (epoch+1)%20 ==0: \n",
    "\t\ttorch.save(encoder.state_dict(), f'{model_save_path}/encoder_{epoch+1}.pth')\n",
    "\t\ttorch.save(decoder.state_dict(), f'{model_save_path}/decoder_{epoch+1}.pth')\n",
    "\n",
    "\t# plot_ae_outputs(encoder,decoder,n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# Plot losses\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.semilogy(diz_loss['train_loss'], label='Train')\n",
    "plt.semilogy(diz_loss['val_loss'], label='Valid')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Average Loss')\n",
    "# plt.grid()\n",
    "plt.legend()\n",
    "plt.title('loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_path=f\"{model_save_path}/encoder.pth\"\n",
    "decoder_path=f\"{model_save_path}/decoder.pth\"\n",
    "torch.save(encoder.state_dict(), encoder_path)\n",
    "torch.save(decoder.state_dict(), decoder_path)\n",
    "\n",
    "encoder=load_encoder(encoder_path, encoded_space_dim)\n",
    "# decoder=load_decoder(decoder_path, 64)\n",
    "encoder = encoder.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 200/200 [00:00<00:00, 586.88it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Enc. Variable 0</th>\n",
       "      <th>Enc. Variable 1</th>\n",
       "      <th>Enc. Variable 2</th>\n",
       "      <th>Enc. Variable 3</th>\n",
       "      <th>Enc. Variable 4</th>\n",
       "      <th>Enc. Variable 5</th>\n",
       "      <th>Enc. Variable 6</th>\n",
       "      <th>Enc. Variable 7</th>\n",
       "      <th>Enc. Variable 8</th>\n",
       "      <th>Enc. Variable 9</th>\n",
       "      <th>...</th>\n",
       "      <th>Enc. Variable 119</th>\n",
       "      <th>Enc. Variable 120</th>\n",
       "      <th>Enc. Variable 121</th>\n",
       "      <th>Enc. Variable 122</th>\n",
       "      <th>Enc. Variable 123</th>\n",
       "      <th>Enc. Variable 124</th>\n",
       "      <th>Enc. Variable 125</th>\n",
       "      <th>Enc. Variable 126</th>\n",
       "      <th>Enc. Variable 127</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.381442</td>\n",
       "      <td>-0.348558</td>\n",
       "      <td>2.011298</td>\n",
       "      <td>2.378877</td>\n",
       "      <td>4.011207</td>\n",
       "      <td>2.152078</td>\n",
       "      <td>3.671695</td>\n",
       "      <td>-2.307898</td>\n",
       "      <td>-2.117263</td>\n",
       "      <td>-1.795021</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.367442</td>\n",
       "      <td>-1.513589</td>\n",
       "      <td>0.921343</td>\n",
       "      <td>-0.732545</td>\n",
       "      <td>-0.985467</td>\n",
       "      <td>-0.122890</td>\n",
       "      <td>1.873032</td>\n",
       "      <td>0.197743</td>\n",
       "      <td>-2.089395</td>\n",
       "      <td>blues</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.563940</td>\n",
       "      <td>-1.761045</td>\n",
       "      <td>2.789470</td>\n",
       "      <td>3.206656</td>\n",
       "      <td>3.536034</td>\n",
       "      <td>3.063056</td>\n",
       "      <td>3.280330</td>\n",
       "      <td>-0.647360</td>\n",
       "      <td>-0.171360</td>\n",
       "      <td>-1.181332</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.053008</td>\n",
       "      <td>-1.627762</td>\n",
       "      <td>-0.504304</td>\n",
       "      <td>-1.154208</td>\n",
       "      <td>-1.397863</td>\n",
       "      <td>1.027245</td>\n",
       "      <td>1.454794</td>\n",
       "      <td>-0.250471</td>\n",
       "      <td>-0.737791</td>\n",
       "      <td>blues</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.797187</td>\n",
       "      <td>-1.808892</td>\n",
       "      <td>0.457424</td>\n",
       "      <td>2.014404</td>\n",
       "      <td>3.105228</td>\n",
       "      <td>1.561529</td>\n",
       "      <td>4.943253</td>\n",
       "      <td>-1.012801</td>\n",
       "      <td>-0.360457</td>\n",
       "      <td>-2.172325</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.492718</td>\n",
       "      <td>-0.510418</td>\n",
       "      <td>0.157625</td>\n",
       "      <td>-0.256850</td>\n",
       "      <td>-2.394171</td>\n",
       "      <td>-0.470994</td>\n",
       "      <td>1.811178</td>\n",
       "      <td>0.456018</td>\n",
       "      <td>-0.669485</td>\n",
       "      <td>blues</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.152784</td>\n",
       "      <td>0.506787</td>\n",
       "      <td>2.091484</td>\n",
       "      <td>2.573900</td>\n",
       "      <td>3.518601</td>\n",
       "      <td>2.026430</td>\n",
       "      <td>3.288156</td>\n",
       "      <td>-1.926359</td>\n",
       "      <td>-2.063732</td>\n",
       "      <td>-1.335913</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.502838</td>\n",
       "      <td>-1.682763</td>\n",
       "      <td>0.494943</td>\n",
       "      <td>-0.873384</td>\n",
       "      <td>-1.212335</td>\n",
       "      <td>-0.045579</td>\n",
       "      <td>1.444954</td>\n",
       "      <td>0.034429</td>\n",
       "      <td>-2.481031</td>\n",
       "      <td>blues</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.065980</td>\n",
       "      <td>-0.221680</td>\n",
       "      <td>2.486100</td>\n",
       "      <td>2.224941</td>\n",
       "      <td>3.563823</td>\n",
       "      <td>2.323706</td>\n",
       "      <td>3.406559</td>\n",
       "      <td>-2.207782</td>\n",
       "      <td>-2.270232</td>\n",
       "      <td>-2.204921</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.474046</td>\n",
       "      <td>-1.298018</td>\n",
       "      <td>0.765351</td>\n",
       "      <td>-1.154986</td>\n",
       "      <td>-1.148235</td>\n",
       "      <td>-0.040773</td>\n",
       "      <td>1.676467</td>\n",
       "      <td>0.265032</td>\n",
       "      <td>-2.408675</td>\n",
       "      <td>blues</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>-1.087605</td>\n",
       "      <td>-1.040545</td>\n",
       "      <td>0.222942</td>\n",
       "      <td>2.564060</td>\n",
       "      <td>2.445760</td>\n",
       "      <td>2.672208</td>\n",
       "      <td>2.661687</td>\n",
       "      <td>-0.765215</td>\n",
       "      <td>-0.534004</td>\n",
       "      <td>0.068985</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.436133</td>\n",
       "      <td>0.526380</td>\n",
       "      <td>0.447376</td>\n",
       "      <td>-0.285004</td>\n",
       "      <td>-2.120241</td>\n",
       "      <td>0.788121</td>\n",
       "      <td>1.440225</td>\n",
       "      <td>-0.294295</td>\n",
       "      <td>-2.020637</td>\n",
       "      <td>jazz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>-0.089029</td>\n",
       "      <td>-1.043051</td>\n",
       "      <td>1.649790</td>\n",
       "      <td>2.370338</td>\n",
       "      <td>2.070582</td>\n",
       "      <td>2.173416</td>\n",
       "      <td>2.881188</td>\n",
       "      <td>-0.434203</td>\n",
       "      <td>-0.866132</td>\n",
       "      <td>-1.254366</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.971723</td>\n",
       "      <td>-0.850460</td>\n",
       "      <td>-0.354602</td>\n",
       "      <td>-0.806806</td>\n",
       "      <td>-1.200743</td>\n",
       "      <td>0.751611</td>\n",
       "      <td>0.923379</td>\n",
       "      <td>-0.437623</td>\n",
       "      <td>-1.520121</td>\n",
       "      <td>jazz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>-1.279167</td>\n",
       "      <td>0.679596</td>\n",
       "      <td>1.841366</td>\n",
       "      <td>2.742856</td>\n",
       "      <td>3.384626</td>\n",
       "      <td>3.742348</td>\n",
       "      <td>2.802095</td>\n",
       "      <td>-1.173532</td>\n",
       "      <td>-1.993186</td>\n",
       "      <td>0.480518</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.817818</td>\n",
       "      <td>0.357723</td>\n",
       "      <td>1.383626</td>\n",
       "      <td>0.419540</td>\n",
       "      <td>-2.481934</td>\n",
       "      <td>-1.255263</td>\n",
       "      <td>2.052042</td>\n",
       "      <td>-0.465156</td>\n",
       "      <td>-3.588765</td>\n",
       "      <td>jazz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>-2.440501</td>\n",
       "      <td>-0.221602</td>\n",
       "      <td>0.031150</td>\n",
       "      <td>2.128637</td>\n",
       "      <td>4.880177</td>\n",
       "      <td>2.448042</td>\n",
       "      <td>4.323021</td>\n",
       "      <td>-1.688197</td>\n",
       "      <td>-1.278314</td>\n",
       "      <td>-0.224936</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.418862</td>\n",
       "      <td>0.614148</td>\n",
       "      <td>0.964384</td>\n",
       "      <td>0.079415</td>\n",
       "      <td>-2.243201</td>\n",
       "      <td>-0.567919</td>\n",
       "      <td>2.939408</td>\n",
       "      <td>0.217444</td>\n",
       "      <td>-1.704966</td>\n",
       "      <td>jazz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>-0.452483</td>\n",
       "      <td>-0.154743</td>\n",
       "      <td>1.765824</td>\n",
       "      <td>2.281112</td>\n",
       "      <td>3.614856</td>\n",
       "      <td>1.997337</td>\n",
       "      <td>3.182144</td>\n",
       "      <td>-1.677971</td>\n",
       "      <td>-1.444511</td>\n",
       "      <td>-1.549230</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.973338</td>\n",
       "      <td>-1.426371</td>\n",
       "      <td>0.540622</td>\n",
       "      <td>-0.864570</td>\n",
       "      <td>-1.088114</td>\n",
       "      <td>0.088309</td>\n",
       "      <td>1.567353</td>\n",
       "      <td>0.079481</td>\n",
       "      <td>-1.930788</td>\n",
       "      <td>jazz</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows  129 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Enc. Variable 0  Enc. Variable 1  Enc. Variable 2  Enc. Variable 3  \\\n",
       "0          -0.381442        -0.348558         2.011298         2.378877   \n",
       "1          -0.563940        -1.761045         2.789470         3.206656   \n",
       "2          -0.797187        -1.808892         0.457424         2.014404   \n",
       "3          -0.152784         0.506787         2.091484         2.573900   \n",
       "4           0.065980        -0.221680         2.486100         2.224941   \n",
       "..               ...              ...              ...              ...   \n",
       "195        -1.087605        -1.040545         0.222942         2.564060   \n",
       "196        -0.089029        -1.043051         1.649790         2.370338   \n",
       "197        -1.279167         0.679596         1.841366         2.742856   \n",
       "198        -2.440501        -0.221602         0.031150         2.128637   \n",
       "199        -0.452483        -0.154743         1.765824         2.281112   \n",
       "\n",
       "     Enc. Variable 4  Enc. Variable 5  Enc. Variable 6  Enc. Variable 7  \\\n",
       "0           4.011207         2.152078         3.671695        -2.307898   \n",
       "1           3.536034         3.063056         3.280330        -0.647360   \n",
       "2           3.105228         1.561529         4.943253        -1.012801   \n",
       "3           3.518601         2.026430         3.288156        -1.926359   \n",
       "4           3.563823         2.323706         3.406559        -2.207782   \n",
       "..               ...              ...              ...              ...   \n",
       "195         2.445760         2.672208         2.661687        -0.765215   \n",
       "196         2.070582         2.173416         2.881188        -0.434203   \n",
       "197         3.384626         3.742348         2.802095        -1.173532   \n",
       "198         4.880177         2.448042         4.323021        -1.688197   \n",
       "199         3.614856         1.997337         3.182144        -1.677971   \n",
       "\n",
       "     Enc. Variable 8  Enc. Variable 9  ...  Enc. Variable 119  \\\n",
       "0          -2.117263        -1.795021  ...          -3.367442   \n",
       "1          -0.171360        -1.181332  ...          -2.053008   \n",
       "2          -0.360457        -2.172325  ...          -3.492718   \n",
       "3          -2.063732        -1.335913  ...          -3.502838   \n",
       "4          -2.270232        -2.204921  ...          -3.474046   \n",
       "..               ...              ...  ...                ...   \n",
       "195        -0.534004         0.068985  ...          -4.436133   \n",
       "196        -0.866132        -1.254366  ...          -1.971723   \n",
       "197        -1.993186         0.480518  ...          -5.817818   \n",
       "198        -1.278314        -0.224936  ...          -4.418862   \n",
       "199        -1.444511        -1.549230  ...          -2.973338   \n",
       "\n",
       "     Enc. Variable 120  Enc. Variable 121  Enc. Variable 122  \\\n",
       "0            -1.513589           0.921343          -0.732545   \n",
       "1            -1.627762          -0.504304          -1.154208   \n",
       "2            -0.510418           0.157625          -0.256850   \n",
       "3            -1.682763           0.494943          -0.873384   \n",
       "4            -1.298018           0.765351          -1.154986   \n",
       "..                 ...                ...                ...   \n",
       "195           0.526380           0.447376          -0.285004   \n",
       "196          -0.850460          -0.354602          -0.806806   \n",
       "197           0.357723           1.383626           0.419540   \n",
       "198           0.614148           0.964384           0.079415   \n",
       "199          -1.426371           0.540622          -0.864570   \n",
       "\n",
       "     Enc. Variable 123  Enc. Variable 124  Enc. Variable 125  \\\n",
       "0            -0.985467          -0.122890           1.873032   \n",
       "1            -1.397863           1.027245           1.454794   \n",
       "2            -2.394171          -0.470994           1.811178   \n",
       "3            -1.212335          -0.045579           1.444954   \n",
       "4            -1.148235          -0.040773           1.676467   \n",
       "..                 ...                ...                ...   \n",
       "195          -2.120241           0.788121           1.440225   \n",
       "196          -1.200743           0.751611           0.923379   \n",
       "197          -2.481934          -1.255263           2.052042   \n",
       "198          -2.243201          -0.567919           2.939408   \n",
       "199          -1.088114           0.088309           1.567353   \n",
       "\n",
       "     Enc. Variable 126  Enc. Variable 127  label  \n",
       "0             0.197743          -2.089395  blues  \n",
       "1            -0.250471          -0.737791  blues  \n",
       "2             0.456018          -0.669485  blues  \n",
       "3             0.034429          -2.481031  blues  \n",
       "4             0.265032          -2.408675  blues  \n",
       "..                 ...                ...    ...  \n",
       "195          -0.294295          -2.020637   jazz  \n",
       "196          -0.437623          -1.520121   jazz  \n",
       "197          -0.465156          -3.588765   jazz  \n",
       "198           0.217444          -1.704966   jazz  \n",
       "199           0.079481          -1.930788   jazz  \n",
       "\n",
       "[200 rows x 129 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "encoded_samples = []\n",
    "for sample in tqdm(test_dataset):\n",
    "    img = sample[0].unsqueeze(0).to(device)\n",
    "    label = sample[1]\n",
    "    # Encode image\n",
    "    encoder.eval()\n",
    "    with torch.no_grad():\n",
    "        encoded_img  = encoder(img)\n",
    "    # Append to list\n",
    "    encoded_img = encoded_img.flatten().cpu().numpy()\n",
    "    encoded_sample = {f\"Enc. Variable {i}\": enc for i, enc in enumerate(encoded_img)}\n",
    "    encoded_sample['label'] = label\n",
    "    encoded_samples.append(encoded_sample)\n",
    "encoded_samples = pd.DataFrame(encoded_samples)\n",
    "encoded_samples.to_csv(f\"{csv_save_path}/gtzan_encoded.csv\", index=False)\n",
    "encoded_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
